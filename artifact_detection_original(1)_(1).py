# -*- coding: utf-8 -*-
"""Artifact_detection_original(1) (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XLHlWYZOhxkG3bPhJ_Bv-YmbdwniOHiS
"""

! git lfs install

! git clone https://www.modelscope.cn/datasets/lzhmark/TUH_EEG_Artifact_Corpus.git

! unzip /content/TUH_EEG_Artifact_Corpus/tuar.zip

! pip install mne

import pandas as pd

# Try using a different delimiter, such as tab ('\t')
data = pd.read_csv('/content/tuh_eeg_artifact/edf/01_tcp_ar/aaaaaaju_s007_t000.csv', delimiter=',',header=6)
data.head()

for i in range(len(data['channel'])):
  data['channel'][i]='EEG'+' '+ data['channel'][i].split('-')[0]+'-REF'

data

data.index=data['channel']

data_ch=data.loc['EEG FP1-REF']

data_ch

import mne

file_path = "/content/tuh_eeg_artifact/edf/01_tcp_ar/aaaaaaju_s005_t000.edf"
raw = mne.io.read_raw_edf(file_path, preload=True)

# Print available channel names
print(raw.ch_names)

# Select data for an existing channel from the list above

channel_name = 'EEG FP1-REF'
data, times = raw[channel_name]
print(f"Data for {channel_name}:")
print(data[0]) # First 10 samples

times

import numpy as np
import pandas as pd
from scipy.stats import kurtosis, skew

# Initialize lists to store features
means = []
std_devs = []
kurtoses = []
skewnesses = []
medians = []
max_vals = []
min_vals = []
ranges = []
labels = []

# Iterate through each segment in data_ch
for i in range(data_ch.shape[0]):
    # Define the range
    lower_bound = data_ch['start_time'].iloc[i]
    upper_bound = data_ch['stop_time'].iloc[i]

    # Get indices where the values fall within the range
    indices = np.where((times >= lower_bound) & (times <= upper_bound))[0]
    selected_data = data[0, indices]

    # Calculate features
    means.append(np.mean(selected_data))
    std_devs.append(np.std(selected_data))
    kurtoses.append(kurtosis(selected_data))
    skewnesses.append(skew(selected_data))
    medians.append(np.median(selected_data))
    max_vals.append(np.max(selected_data))
    min_vals.append(np.min(selected_data))
    ranges.append(np.max(selected_data) - np.min(selected_data))

    # Add the label
    labels.append(data_ch['label'].iloc[i])

# Create a DataFrame with the calculated features
features_df = pd.DataFrame({
    'Mean': means,
    'Standard Deviation': std_devs,
    'Kurtosis': kurtoses,
    'Skewness': skewnesses,
    'Median': medians,
    'Max': max_vals,
    'Min': min_vals,
    'Range': ranges,
    'Label': labels
})

# Display the resulting DataFrame
print(features_df)

features_df = pd.concat([features_df, features_df])

features_df = pd.concat([features_df, features_df])

# prompt: train test split

from sklearn.model_selection import train_test_split

# Assuming 'features_df' is your DataFrame with features and labels
X = features_df.drop('Label', axis=1)  # Features
y = features_df['Label']  # Labels

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # 80% training and 20% test

# Print the shapes of the resulting datasets
print("X_train shape:", X_train.shape)
print("y_train shape:", y_train.shape)
print("X_test shape:", X_test.shape)
print("y_test shape:", y_test.shape)

# prompt: standardize zation and label binarization

from sklearn.preprocessing import StandardScaler, LabelBinarizer

# Initialize StandardScaler
scaler = StandardScaler()

# Fit and transform the training features
X_train_scaled = scaler.fit_transform(X_train)

# Transform the testing features using the same scaler
X_test_scaled = scaler.transform(X_test)

# Initialize LabelBinarizer
lb = LabelBinarizer()

# Fit and transform the training labels
y_train_bin = lb.fit_transform(y_train)

# Transform the testing labels using the same binarizer
y_test_bin = lb.transform(y_test)

# Print the shapes of the transformed datasets
print("X_train_scaled shape:", X_train_scaled.shape)
print("y_train_bin shape:", y_train_bin.shape)
print("X_test_scaled shape:", X_test_scaled.shape)
print("y_test_bin shape:", y_test_bin.shape)

# prompt: ensemble of svm , rf and navies

from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import VotingClassifier

# Initialize the individual classifiers
svm_clf = SVC(probability=True)  # probability=True is required for VotingClassifier with soft voting
rf_clf = RandomForestClassifier()
nb_clf = GaussianNB()

# Create the ensemble classifier using VotingClassifier with soft voting
ensemble_clf = VotingClassifier(estimators=[('svm', svm_clf), ('rf', rf_clf), ('nb', nb_clf)], voting='soft')

# Train the ensemble classifier
ensemble_clf.fit(X_train_scaled, y_train)

# Make predictions on the test set
y_pred = ensemble_clf.predict(X_test_scaled)

# Evaluate the ensemble classifier (example using accuracy)
from sklearn.metrics import accuracy_score
accuracy = accuracy_score(y_test, y_pred)
print(f"Ensemble Accuracy: {accuracy}")

from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,confusion_matrix

precision = precision_score(y_test, y_pred, average='weighted')
print(f"Ensemble Precision: {precision}")
recall = recall_score(y_test, y_pred, average='weighted')
print(f"Ensemble Recall: {recall}")
f1 = f1_score(y_test, y_pred, average='weighted')
print(f"Ensemble F1 Score: {f1}")

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Assuming y_test and y_pred are defined from previous code
cm = confusion_matrix(y_test, y_pred)

# Plot the confusion matrix using seaborn
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=lb.classes_, yticklabels=lb.classes_)
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix of SVC_RF_GaussianNB Model")
plt.show()

from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

# Binarize the true labels
y_test_bin = label_binarize(y_test, classes=lb.classes_)
y_pred_bin = label_binarize(y_pred, classes=lb.classes_)
# Compute ROC curve and AUC for each class
n_classes = y_test_bin.shape[1]
fpr = dict()
tpr = dict()
roc_auc = dict()

for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_bin[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Plot the ROC curves for each class
plt.figure(figsize=(8, 6))
for i in range(n_classes):
    plt.plot(fpr[i], tpr[i], lw=2, label=f'ROC curve (area = {roc_auc[i]:.2f}) for class {lb.classes_[i]}')

plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Random chance line
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve of SVC_RF_GaussianNB Model')
plt.legend(loc="lower right")
plt.show()

"""# **CNN, LSTM, and a Fully Connected Neural Network (FCNN)**"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv1D, LSTM, Flatten, Dropout
from tensorflow.keras.optimizers import Adam
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical

# Encode labels
le = LabelEncoder()
y_train_enc = to_categorical(le.fit_transform(y_train))
y_test_enc = to_categorical(le.transform(y_test))

# Reshape input for CNN and LSTM
X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))
X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))

# CNN Model
cnn_model = Sequential([
    Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train_reshaped.shape[1], 1)),
    Flatten(),
    Dense(64, activation='relu'),
    Dropout(0.3),
    Dense(y_train_enc.shape[1], activation='softmax')
])
cnn_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

# LSTM Model
lstm_model = Sequential([
    LSTM(50, return_sequences=True, input_shape=(X_train_reshaped.shape[1], 1)),
    LSTM(50),
    Dense(64, activation='relu'),
    Dropout(0.3),
    Dense(y_train_enc.shape[1], activation='softmax')
])
lstm_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

# FCNN Model
fcnn_model = Sequential([
    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),
    Dropout(0.3),
    Dense(64, activation='relu'),
    Dense(y_train_enc.shape[1], activation='softmax')
])
fcnn_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

# Train models
cnn_model.fit(X_train_reshaped, y_train_enc, epochs=50, batch_size=32, validation_data=(X_test_reshaped, y_test_enc))
lstm_model.fit(X_train_reshaped, y_train_enc, epochs=50, batch_size=32, validation_data=(X_test_reshaped, y_test_enc))
fcnn_model.fit(X_train_scaled, y_train_enc, epochs=50, batch_size=32, validation_data=(X_test_scaled, y_test_enc))

# Evaluate models
cnn_acc = cnn_model.evaluate(X_test_reshaped, y_test_enc, verbose=0)[1]
lstm_acc = lstm_model.evaluate(X_test_reshaped, y_test_enc, verbose=0)[1]
fcnn_acc = fcnn_model.evaluate(X_test_scaled, y_test_enc, verbose=0)[1]

print(f"CNN Accuracy: {cnn_acc:.4f}")
print(f"LSTM Accuracy: {lstm_acc:.4f}")
print(f"FCNN Accuracy: {fcnn_acc:.4f}")

# Ensemble (Average Predictions)
import numpy as np

cnn_preds = cnn_model.predict(X_test_reshaped)
lstm_preds = lstm_model.predict(X_test_reshaped)
fcnn_preds = fcnn_model.predict(X_test_scaled)

ensemble_preds = (cnn_preds + lstm_preds + fcnn_preds) / 3
y_pred_ensemble = np.argmax(ensemble_preds, axis=1)
y_test_labels = np.argmax(y_test_enc, axis=1)

# Evaluate ensemble
from sklearn.metrics import accuracy_score, classification_report
ensemble_acc = accuracy_score(y_test_labels, y_pred_ensemble)
print(f"Ensemble Model Accuracy: {ensemble_acc:.4f}")
print(classification_report(y_test_labels, y_pred_ensemble))
ensemble_pre=precision_score(y_test_labels, y_pred_ensemble, average='weighted')
print(f"Ensemble Precision: {ensemble_pre}")
ensemble_recall=recall_score(y_test_labels, y_pred_ensemble, average='weighted')
print(f"Ensemble Recall: {ensemble_recall}")
ensemble_f1=f1_score(y_test_labels, y_pred_ensemble,average='weighted')
print(f"Ensemble F1 Score: {ensemble_f1}")

# Confusion Matrix
cm = confusion_matrix(y_test_labels, y_pred_ensemble)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix of CNN_LSTM_FCNN Model")
plt.show()

# ROC Curve
y_test_bin = to_categorical(y_test_labels)
y_pred_bin = to_categorical(y_pred_ensemble)
n_classes = y_test_bin.shape[1]
fpr, tpr, roc_auc = {}, {}, {}

for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], ensemble_preds[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

plt.figure(figsize=(8, 6))
for i in range(n_classes):
    plt.plot(fpr[i], tpr[i], lw=2, label=f'ROC curve (area = {roc_auc[i]:.2f}) for class {le.classes_[i]}')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROCCurve of CNN_LSTM_FCNN Model')
plt.legend(loc="lower right")
plt.show()



"""# **GRU_DNN**"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, GRU, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical

# Encode labels
le = LabelEncoder()
y_train_enc = to_categorical(le.fit_transform(y_train))
y_test_enc = to_categorical(le.transform(y_test))

# GRU Model
gru_model = Sequential([
    GRU(64, return_sequences=True, input_shape=(X_train_scaled.shape[1], 1)),
    GRU(64),
    BatchNormalization(),
    Dense(64, activation='relu'),
    Dropout(0.3),
    Dense(y_train_enc.shape[1], activation='softmax')
])
gru_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

# Deep Neural Network (DNN) Model
dnn_model = Sequential([
    Dense(256, activation='relu', input_shape=(X_train_scaled.shape[1],)),
    BatchNormalization(),
    Dropout(0.3),
    Dense(128, activation='relu'),
    Dropout(0.3),
    Dense(y_train_enc.shape[1], activation='softmax')
])
dnn_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

# Train models
gru_model.fit(X_train_scaled, y_train_enc, epochs=50, batch_size=32, validation_data=(X_test_scaled, y_test_enc))
dnn_model.fit(X_train_scaled, y_train_enc, epochs=50, batch_size=32, validation_data=(X_test_scaled, y_test_enc))

# Evaluate models
gru_acc = gru_model.evaluate(X_test_scaled, y_test_enc, verbose=0)[1]
dnn_acc = dnn_model.evaluate(X_test_scaled, y_test_enc, verbose=0)[1]

print(f"GRU Accuracy: {gru_acc:.4f}")
print(f"DNN Accuracy: {dnn_acc:.4f}")

# Ensemble (Average Predictions)
import numpy as np

gru_preds = gru_model.predict(X_test_scaled)
dnn_preds = dnn_model.predict(X_test_scaled)

ensemble_preds = (gru_preds + dnn_preds) / 2
y_pred_ensemble = np.argmax(ensemble_preds, axis=1)
y_test_labels = np.argmax(y_test_enc, axis=1)

# Evaluate ensemble
from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score
ensemble_acc = accuracy_score(y_test_labels, y_pred_ensemble)
print(f"Ensemble Model Accuracy: {ensemble_acc:.4f}")
print(classification_report(y_test_labels, y_pred_ensemble))
ensemble_pre=precision_score(y_test_labels, y_pred_ensemble, average='weighted')
print(f"Ensemble Precision: {ensemble_pre}")
ensemble_recall=recall_score(y_test_labels, y_pred_ensemble, average='weighted')
print(f"Ensemble Recall: {ensemble_recall}")
ensemble_f1=f1_score(y_test_labels, y_pred_ensemble,average='weighted')
print(f"Ensemble F1 Score: {ensemble_f1}")

# Confusion Matrix
cm = confusion_matrix(y_test_labels, y_pred_ensemble)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix of GRU_DNN Model")
plt.show()

# ROC Curve
y_test_bin = to_categorical(y_test_labels)
y_pred_bin = to_categorical(y_pred_ensemble)
n_classes = y_test_bin.shape[1]
fpr, tpr, roc_auc = {}, {}, {}

for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], ensemble_preds[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

plt.figure(figsize=(8, 6))
for i in range(n_classes):
    plt.plot(fpr[i], tpr[i], lw=2, label=f'ROC curve (area = {roc_auc[i]:.2f}) for class {le.classes_[i]}')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve of GRU_DNN Model')
plt.legend(loc="lower right")
plt.show()

"""# **LSTM_DNN Model**"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, GRU, Dropout, BatchNormalization, LSTM
from tensorflow.keras.optimizers import Adam
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc

# Encode labels
le = LabelEncoder()
y_train_enc = to_categorical(le.fit_transform(y_train))
y_test_enc = to_categorical(le.transform(y_test))

# LSTM Model
lstm_model = Sequential([
    LSTM(64, return_sequences=True, input_shape=(X_train_scaled.shape[1], 1)),
    LSTM(64),
    BatchNormalization(),
    Dense(64, activation='relu'),
    Dropout(0.3),
    Dense(y_train_enc.shape[1], activation='softmax')
])
lstm_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

# Deep Neural Network (DNN) Model
dnn_model = Sequential([
    Dense(256, activation='relu', input_shape=(X_train_scaled.shape[1],)),
    BatchNormalization(),
    Dropout(0.3),
    Dense(128, activation='relu'),
    Dropout(0.3),
    Dense(y_train_enc.shape[1], activation='softmax')
])
dnn_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

# Train models
lstm_model.fit(X_train_scaled, y_train_enc, epochs=50, batch_size=32, validation_data=(X_test_scaled, y_test_enc))
dnn_model.fit(X_train_scaled, y_train_enc, epochs=50, batch_size=32, validation_data=(X_test_scaled, y_test_enc))

# Evaluate models
lstm_acc = lstm_model.evaluate(X_test_scaled, y_test_enc, verbose=0)[1]
dnn_acc = dnn_model.evaluate(X_test_scaled, y_test_enc, verbose=0)[1]

print(f"LSTM Accuracy: {lstm_acc:.4f}")
print(f"DNN Accuracy: {dnn_acc:.4f}")

# Ensemble (Average Predictions)
lstm_preds = lstm_model.predict(X_test_scaled)
dnn_preds = dnn_model.predict(X_test_scaled)
ensemble_preds = (lstm_preds + dnn_preds) / 2
y_pred_ensemble = np.argmax(ensemble_preds, axis=1)
y_test_labels = np.argmax(y_test_enc, axis=1)

# Evaluate ensemble
ensemble_acc = accuracy_score(y_test_labels, y_pred_ensemble)
print(f"Ensemble Model Accuracy: {ensemble_acc:.4f}")
print(classification_report(y_test_labels, y_pred_ensemble))
ensemble_pre=precision_score(y_test_labels, y_pred_ensemble, average='weighted')
print(f"Ensemble Precision: {ensemble_pre}")
ensemble_recall=recall_score(y_test_labels, y_pred_ensemble, average='weighted')
print(f"Ensemble Recall: {ensemble_recall}")
ensemble_f1=f1_score(y_test_labels, y_pred_ensemble,average='weighted')
print(f"Ensemble F1 Score: {ensemble_f1}")

# Confusion Matrix
cm = confusion_matrix(y_test_labels, y_pred_ensemble)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix of LSTM_DNN Model")
plt.show()

# ROC Curve
y_test_bin = to_categorical(y_test_labels)
y_pred_bin = to_categorical(y_pred_ensemble)
n_classes = y_test_bin.shape[1]
fpr, tpr, roc_auc = {}, {}, {}

for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], ensemble_preds[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

plt.figure(figsize=(8, 6))
for i in range(n_classes):
    plt.plot(fpr[i], tpr[i], lw=2, label=f'ROC curve (area = {roc_auc[i]:.2f}) for class {le.classes_[i]}')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve of LSTM_DNN Model')
plt.legend(loc="lower right")
plt.show()